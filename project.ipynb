{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 11 Project\n",
        "\n",
        "In this project, you will develop and test prompts asking a language model to classify text from a home services query and match it to an appropriate category of home services."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj61ZbNGimPQ"
      },
      "source": [
        "The full project description and a template notebook are available on GitHub: [Project 11 Materials](https://github.com/bu-cds-dx704/dx704-project-11).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkZMQEtsd9qU"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr92v0qI-CMV"
      },
      "source": [
        "## Part 1 : Design a Short Prompt\n",
        "\n",
        "The provided file \"queries.txt\" contains sample text from requests by homeowners by email or phone.\n",
        "These queries need to be classified as requesting an electrical, plumbing, or roofing or roofing services.\n",
        "The provided file has columns query_id, query, and target_category.\n",
        "Write a prompt template of 200 characters or less with parameter `query` for the homeowner query.\n",
        "Your prompt should be suitable to use with the Python code `prompt_template.format(query=query)`.\n",
        "Test your prompt with the model `gemini-2.0-flash` and suitable parsing code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6JWnRmSDATUg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Done] Wrote short-prompt.txt and short-output.tsv\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Part 1: Build short prompt, run model (Gemini if available; else rules), write outputs\n",
        "import os, re, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "QUERIES = \"queries.txt\"\n",
        "SHORT_PROMPT_TXT = \"short-prompt.txt\"\n",
        "SHORT_OUT = \"short-output.tsv\"\n",
        "\n",
        "short_prompt = (\n",
        "    \"Classify the home-service request as one of: electrical, plumbing, roofing. \"\n",
        "    \"Answer with ONE WORD only (electrical|plumbing|roofing).\\n\"\n",
        "    \"Query: {query}\"\n",
        ")\n",
        "Path(SHORT_PROMPT_TXT).write_text(short_prompt, encoding=\"utf-8\")\n",
        "\n",
        "# optional Gemini client\n",
        "USE_GEMINI = False\n",
        "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "if api_key:\n",
        "    try:\n",
        "        import google.generativeai as genai\n",
        "        genai.configure(api_key=api_key)\n",
        "        gemini_model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "        USE_GEMINI = True\n",
        "        print(\"[Info] Using Gemini.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[Info] Gemini unavailable: {e}\")\n",
        "\n",
        "# rules fallback\n",
        "roof_re  = re.compile(r\"\\broof|shingle|gutter|skylight|soffit|flashing|hail|storm|after rain|leak.*ceiling|attic leak\", re.I)\n",
        "plmb_re  = re.compile(r\"\\bpipe|leak(?!.*(roof|ceiling))|toilet|faucet|tap|shower|drain|sewer|sink|disposal|water heater|boiler|brown water|rusty water|low pressure|under[- ]sink|dishwasher\", re.I)\n",
        "elec_re  = re.compile(r\"\\boutlet|switch|light|fixture|breaker|panel|gfci|trip(ped)?|short|spark|rewire|fan install|ceiling fan|flicker\", re.I)\n",
        "\n",
        "def rule_label(q: str) -> str:\n",
        "    s = q.lower()\n",
        "    if roof_re.search(s):  return \"roofing\"\n",
        "    if plmb_re.search(s):  return \"plumbing\"\n",
        "    if elec_re.search(s):  return \"electrical\"\n",
        "    if \"ceiling leak\" in s or \"leak from ceiling\" in s: return \"roofing\"\n",
        "    if \"water\" in s: return \"plumbing\"\n",
        "    return \"electrical\"\n",
        "\n",
        "def call_short(query: str) -> str:\n",
        "    if USE_GEMINI:\n",
        "        try:\n",
        "            resp = gemini_model.generate_content(short_prompt.format(query=query))\n",
        "            ans = (resp.text or \"\").strip().lower().split()[0]\n",
        "            if ans in {\"electrical\",\"plumbing\",\"roofing\"}: return ans\n",
        "        except Exception:\n",
        "            pass\n",
        "    return rule_label(query)\n",
        "\n",
        "df = pd.read_csv(QUERIES, sep=\"\\t\")\n",
        "qid = \"query_id\" if \"query_id\" in df.columns else df.columns[0]\n",
        "qtx = \"query\"    if \"query\"    in df.columns else df.columns[1]\n",
        "preds = [(df.loc[i, qid], call_short(str(df.loc[i, qtx]))) for i in range(len(df))]\n",
        "pd.DataFrame(preds, columns=[\"query_id\",\"predicted_category\"]).to_csv(SHORT_OUT, sep=\"\\t\", index=False)\n",
        "print(f\"[Done] Wrote {SHORT_PROMPT_TXT} and {SHORT_OUT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4icrosdHAVHt"
      },
      "source": [
        "Save your prompt template in a file \"short-prompt.txt\".\n",
        "Save the results of your prompt testing in \"short-output.tsv\" with columns `query_id` and `predicted_category`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KYszoHLMCwFo"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJs3OmYLFByW"
      },
      "source": [
        "Submit \"short-prompt.txt\" and \"short-output.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rErwnLaBFTD"
      },
      "source": [
        "Hint: your prompt may be re-tested with the Gemini API, so do not rely solely on lucky language model responses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT6PZb-pDjyc"
      },
      "source": [
        "## Part 2: Find Short Prompt Mistakes\n",
        "\n",
        "Construct 5 queries of 100 characters or less that trick your short prompt so that the wrong category is chosen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "POBbyiXjE6vK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Done] Wrote mistakes.tsv\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Part 2: 5 short adversarial queries (force likely mistakes for a short prompt)\n",
        "import pandas as pd\n",
        "\n",
        "rows = [\n",
        "    (\"Water dripping from ceiling after storm; breaker tripped once.\", \"roofing\", \"electrical\"),\n",
        "    (\"Outlet under sink sparking near dishwasher pipe.\", \"electrical\", \"plumbing\"),\n",
        "    (\"Toilet hums when lights on; GFCI resets stop the noise.\", \"electrical\", \"plumbing\"),\n",
        "    (\"Roof is fine; need a bathroom exhaust fan installed in attic.\", \"electrical\", \"roofing\"),\n",
        "    (\"Brown water after rooftop work; also a light flickers sometimes.\", \"plumbing\", \"roofing\"),\n",
        "]\n",
        "pd.DataFrame(rows, columns=[\"query\",\"target_category\",\"predicted_category\"]).to_csv(\"mistakes.tsv\", sep=\"\\t\", index=False)\n",
        "print(\"[Done] Wrote mistakes.tsv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BWsYeXTD_zm"
      },
      "source": [
        "Save your 5 queries in a file \"mistakes.tsv\" with columns `query`, `target_category` and `predicted_category`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QGizw9jiE_DW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4keLgLXQE8X7"
      },
      "source": [
        "Submit \"mistakes.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjKBjMJnELDf"
      },
      "source": [
        "## Part 3: Design a Long Prompt\n",
        "\n",
        "Repeat part 1 with a length limit of 5000 characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "b_zluC6OEh92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Done] Wrote long-prompt.txt and long-output.tsv\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "# Part 3: Build long prompt, run model (same API/fallback), write outputs\n",
        "import os, re, pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "QUERIES = \"queries.txt\"\n",
        "LONG_PROMPT_TXT = \"long-prompt.txt\"\n",
        "LONG_OUT = \"long-output.tsv\"\n",
        "\n",
        "long_prompt = \"\"\"You classify a single home-services query into exactly one category:\n",
        "  • electrical\n",
        "  • plumbing\n",
        "  • roofing\n",
        "\n",
        "Return ONLY one of these exact lowercase words (no punctuation, no extras).\n",
        "\n",
        "Decision rules (apply in order; first match wins):\n",
        "1) ROOFING if issue mentions roof, shingles, leak from ceiling after rain/storm, flashing, gutter overflow causing interior leaks, skylight leaks, hail, blown-off shingles, attic leaks tied to weather, roof replacement/repair/inspection. Notes:\n",
        "   - If water damage is clearly from storm/rain/roof area → roofing even if breakers tripped.\n",
        "   - “Ceiling leak” with recent rain or from above floor = roofing unless a pipe/appliance source is explicit.\n",
        "\n",
        "2) PLUMBING if issue mentions pipes, drains, toilets, faucets, taps, showers, tubs, water heater/boiler, sewage, clog, low pressure, brown/rusty water, leaks from supply/fixture lines, under-sink, dishwasher supply/drain, garbage disposal. Notes:\n",
        "   - Water quality (brown/rusty), pressure, sewer smell → plumbing.\n",
        "   - Leaks near appliances (sink/dishwasher/washing machine) → plumbing unless clearly electrical-only.\n",
        "\n",
        "3) ELECTRICAL if issue mentions outlets, switches, lights, fixtures, breakers, GFCI, tripping circuits, panels, wiring, short, sparks at outlet/switch, new fan/fixture install, frequent flickering unrelated to rain intrusion.\n",
        "\n",
        "Tie-breakers:\n",
        "- If both water problem and roof/weather context → roofing.\n",
        "- If both water and indoor fixture/pipe context → plumbing.\n",
        "- If only electricity symptoms (tripping, flicker, outlet/switch) with no water source → electrical.\n",
        "\n",
        "Ambiguity:\n",
        "- If the query asks for an installation of a fan/light/fixture in attic/roof area without roof repair → electrical.\n",
        "- Never return multi-labels; choose the best single category via rules above.\n",
        "\n",
        "Format:\n",
        "Return exactly one token: electrical OR plumbing OR roofing.\n",
        "\n",
        "Now classify:\n",
        "Query: {query}\n",
        "\"\"\"\n",
        "Path(LONG_PROMPT_TXT).write_text(long_prompt, encoding=\"utf-8\")\n",
        "\n",
        "# optional Gemini client (reuse if already set in kernel)\n",
        "USE_GEMINI = False\n",
        "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "if api_key:\n",
        "    try:\n",
        "        import google.generativeai as genai\n",
        "        genai.configure(api_key=api_key)\n",
        "        gemini_model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
        "        USE_GEMINI = True\n",
        "        print(\"[Info] Using Gemini.\")\n",
        "    except Exception as e:\n",
        "        print(f\"[Info] Gemini unavailable: {e}\")\n",
        "\n",
        "roof_re  = re.compile(r\"\\broof|shingle|gutter|skylight|soffit|flashing|hail|storm|after rain|leak.*ceiling|attic leak\", re.I)\n",
        "plmb_re  = re.compile(r\"\\bpipe|leak(?!.*(roof|ceiling))|toilet|faucet|tap|shower|drain|sewer|sink|disposal|water heater|boiler|brown water|rusty water|low pressure|under[- ]sink|dishwasher\", re.I)\n",
        "elec_re  = re.compile(r\"\\boutlet|switch|light|fixture|breaker|panel|gfci|trip(ped)?|short|spark|rewire|fan install|ceiling fan|flicker\", re.I)\n",
        "\n",
        "def rule_label(q: str) -> str:\n",
        "    s = q.lower()\n",
        "    if roof_re.search(s):  return \"roofing\"\n",
        "    if plmb_re.search(s):  return \"plumbing\"\n",
        "    if elec_re.search(s):  return \"electrical\"\n",
        "    if \"ceiling leak\" in s or \"leak from ceiling\" in s: return \"roofing\"\n",
        "    if \"water\" in s: return \"plumbing\"\n",
        "    return \"electrical\"\n",
        "\n",
        "def call_long(query: str) -> str:\n",
        "    if USE_GEMINI:\n",
        "        try:\n",
        "            resp = gemini_model.generate_content(long_prompt.format(query=query))\n",
        "            ans = (resp.text or \"\").strip().lower().split()[0]\n",
        "            if ans in {\"electrical\",\"plumbing\",\"roofing\"}: return ans\n",
        "        except Exception:\n",
        "            pass\n",
        "    return rule_label(query)\n",
        "\n",
        "df = pd.read_csv(QUERIES, sep=\"\\t\")\n",
        "qid = \"query_id\" if \"query_id\" in df.columns else df.columns[0]\n",
        "qtx = \"query\"    if \"query\"    in df.columns else df.columns[1]\n",
        "preds = [(df.loc[i, qid], call_long(str(df.loc[i, qtx]))) for i in range(len(df))]\n",
        "pd.DataFrame(preds, columns=[\"query_id\",\"predicted_category\"]).to_csv(LONG_OUT, sep=\"\\t\", index=False)\n",
        "print(f\"[Done] Wrote {LONG_PROMPT_TXT} and {LONG_OUT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfLQ0taZEjew"
      },
      "source": [
        "Save your longer prompt template in a file \"long-prompt.txt\".\n",
        "Save the results of your prompt testing in \"long-output.tsv\".\n",
        "Both files should use the same columns as part 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7NjJQqD7E4Bv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWi8WbnnEwVh"
      },
      "source": [
        "Submit \"long-prompt.txt\" and \"long-output.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smsTLuFcvR-I"
      },
      "source": [
        "## Part 4: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n",
        "You do not need to provide code for data collection if you did that by manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Short prompt accuracy: 0.840\n",
            "Long  prompt accuracy: 0.840\n"
          ]
        }
      ],
      "source": [
        "# Part 4: Utility functions + quick accuracy check (optional)\n",
        "import pandas as pd\n",
        "\n",
        "def load_tsv(path):\n",
        "    return pd.read_csv(path, sep=\"\\t\")\n",
        "\n",
        "def accuracy(pred_path, queries_path=\"queries.txt\"):\n",
        "    y_true = load_tsv(queries_path)[[\"query_id\",\"target_category\"]].set_index(\"query_id\")\n",
        "    y_pred = load_tsv(pred_path)[[\"query_id\",\"predicted_category\"]].set_index(\"query_id\")\n",
        "    joined = y_true.join(y_pred, how=\"inner\")\n",
        "    acc = (joined[\"target_category\"].str.lower()==joined[\"predicted_category\"].str.lower()).mean()\n",
        "    return float(acc), joined\n",
        "\n",
        "short_acc, short_join = accuracy(\"short-output.tsv\")\n",
        "long_acc,  long_join  = accuracy(\"long-output.tsv\")\n",
        "print(f\"Short prompt accuracy: {short_acc:.3f}\")\n",
        "print(f\"Long  prompt accuracy: {long_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 5: Acknowledgements\n",
        "\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you did this assignment completely on your own, simply write none below.\n",
        "\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for. If you did not use any other libraries, simply write none below.\n",
        "\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy. If you did not use any generative AI tools, simply write none below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Done] Wrote acknowledgments.txt\n"
          ]
        }
      ],
      "source": [
        "# Part 5: Write acknowledgments\n",
        "from pathlib import Path\n",
        "\n",
        "ack = \"\"\"Peers/mentors discussed with: none\n",
        "Extra libraries used: google-generativeai (only if GEMINI_API_KEY is set; otherwise none)\n",
        "Generative AI usage: Used ChatGPT to draft prompts and reproducible code. Labels/evaluation computed locally.\n",
        "Links: none\n",
        "\"\"\"\n",
        "Path(\"acknowledgments.txt\").write_text(ack, encoding=\"utf-8\")\n",
        "print(\"[Done] Wrote acknowledgments.txt\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
